{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия. Отчет\n",
    "\n",
    "### 1. Какое качество получилось у логистической регрессии над всеми исходными признаками? Как оно соотносится с качеством градиентного бустинга? Чем вы можете объяснить эту разницу? Быстрее ли работает логистическая регрессия по сравнению с градиентным бустингом?: \n",
    "\n",
    "Наилучшее качество (С=100000): 0.72. Это приблизительно равно качеству градиентного бустинга с 400 деревьями.\n",
    "Логистическая регрессия работает быстрее градиентного бустинга примерно в 3 раза (для 30 деревьев и С=0.00001) и в 67 раз (для 400 деревьев и С=10000000).\n",
    "\n",
    "### 2. Как влияет на качество логистической регрессии удаление категориальных признаков (укажите новое значение метрики качества)? Чем вы можете объяснить это изменение?\n",
    "\n",
    "Удаление категориальных признаков практически не влияет на качество регрессии. Значение метрики - 0.71\n",
    "\n",
    "### 3. Сколько различных идентификаторов героев существует в данной игре?\n",
    "\n",
    "112\n",
    "\n",
    "### 4. Какое получилось качество при добавлении \"мешка слов\" по героям? Улучшилось ли оно по сравнению с предыдущим вариантом? Чем вы можете это объяснить?\n",
    "\n",
    "0.75. Качество улучшилось. Это связано с тем, что вместо удаления информативных категориальных признаков мы заменили их на числовые аналоги с сохранением их смысла. Таким образом мы не потеряли признаки, которые, как оказалось, имеют немалый вес.\n",
    "\n",
    "### 5. Какое минимальное и максимальное значение прогноза на тестовой выборке получилось у лучшего из алгоритмов?\n",
    "\n",
    "Минимальные 0.009\n",
    "\n",
    "Максимальное 0.997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from __future__ import division\n",
    "\n",
    "data = pd.read_csv('data/features.csv', index_col='match_id')\n",
    "data_heroes = pd.read_csv('data/dictionaries/heroes.csv')\n",
    "data_test = pd.read_csv('data/features_test.csv', index_col='match_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Оцените качество логистической регрессии (sklearn.linear_model.LogisticRegression с L2-регуляризацией) с помощью кросс-валидации по той же схеме, которая использовалась для градиентного бустинга. Подберите при этом лучший параметр регуляризации (C)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed:  0:00:04.130000\n",
      "c: 1e-05  Score: [ 0.6931532   0.69481539  0.69571379  0.69513159  0.69699445]\n",
      "Time elapsed:  0:00:10.534000\n",
      "c: 0.001  Score: [ 0.71449541  0.71577214  0.71625974  0.71697301  0.71831738]\n",
      "Time elapsed:  0:00:14.494000\n",
      "c: 0.1  Score: [ 0.71462192  0.71617479  0.71619187  0.71737596  0.7182712 ]\n",
      "Time elapsed:  0:00:15.158000\n",
      "c: 1  Score: [ 0.71461815  0.71617185  0.71618338  0.7173762   0.71826341]\n",
      "Time elapsed:  0:00:15.052000\n",
      "c: 10  Score: [ 0.71461695  0.71617179  0.71618281  0.71737669  0.7182632 ]\n",
      "Time elapsed:  0:00:15.294000\n",
      "c: 1000  Score: [ 0.71461693  0.71617214  0.7161825   0.71737659  0.71826346]\n",
      "Time elapsed:  0:00:14.538000\n",
      "c: 100000  Score: [ 0.71461693  0.71617215  0.71618252  0.71737661  0.71826345]\n",
      "Time elapsed:  0:00:14.592000\n",
      "c: 10000000  Score: [ 0.71461693  0.71617215  0.71618252  0.71737661  0.71826345]\n"
     ]
    }
   ],
   "source": [
    "data.fillna(value=0, inplace=True)\n",
    "X = data.drop([\n",
    "    'duration', \n",
    "    'radiant_win', \n",
    "    'tower_status_radiant', \n",
    "    'tower_status_dire', \n",
    "    'barracks_status_radiant',\n",
    "    'barracks_status_dire'\n",
    "], axis=1)\n",
    "y_train = data['radiant_win']\n",
    "scaler = StandardScaler()\n",
    "X.fillna(value=0, inplace=True)\n",
    "X_train = scaler.fit_transform(X)\n",
    "\n",
    "scores = []\n",
    "C = [0.00001, 0.001, 0.1, 1, 10, 1000, 100000, 10000000]\n",
    "kf = KFold(n=len(y_train.values), n_folds=5, shuffle=True, random_state=42)\n",
    "for c in C:\n",
    "    clf = LogisticRegression(C=c, random_state=42)\n",
    "    start_time = datetime.datetime.now()\n",
    "    score = cross_val_score(clf, X_train, y_train, cv=kf, scoring='roc_auc')\n",
    "    print 'Time elapsed: ', datetime.datetime.now() - start_time\n",
    "    print 'c:', c, ' Score:', score\n",
    "    scores.append(np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 2. Уберите категориальные признаки из выборки, и проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed:  0:00:03.329000\n",
      "c: 1e-05  Score: [ 0.69315871  0.69479523  0.69564582  0.69518196  0.69694992]\n",
      "Time elapsed:  0:00:10.308000\n",
      "c: 0.001  Score: [ 0.71454097  0.71576992  0.71623277  0.71701307  0.71829979]\n",
      "Time elapsed:  0:00:14.315000\n",
      "c: 0.1  Score: [ 0.7146576   0.71617303  0.71617642  0.71739988  0.71825905]\n",
      "Time elapsed:  0:00:14.589000\n",
      "c: 1  Score: [ 0.71465418  0.7161692   0.7161687   0.71739792  0.71825005]\n",
      "Time elapsed:  0:00:14.410000\n",
      "c: 10  Score: [ 0.71465377  0.71616925  0.71616883  0.71739829  0.71824948]\n",
      "Time elapsed:  0:00:14.420000\n",
      "c: 1000  Score: [ 0.71465364  0.71616924  0.71616864  0.71739836  0.71824937]\n",
      "Time elapsed:  0:00:14.659000\n",
      "c: 100000  Score: [ 0.71465364  0.71616924  0.7161686   0.71739837  0.71824937]\n",
      "Time elapsed:  0:00:15.522000\n",
      "c: 10000000  Score: [ 0.71465364  0.71616924  0.7161686   0.71739837  0.71824937]\n"
     ]
    }
   ],
   "source": [
    "X = data.drop([\n",
    "    'duration', \n",
    "    'radiant_win', \n",
    "    'tower_status_radiant', \n",
    "    'tower_status_dire', \n",
    "    'barracks_status_radiant',\n",
    "    'barracks_status_dire',\n",
    "    'lobby_type',\n",
    "], axis=1)\n",
    "for n in range(1, 6):\n",
    "    X.drop(['r{}_hero'.format(n)], axis=1)\n",
    "    X.drop(['d{}_hero'.format(n)], axis=1)\n",
    "y_train = data['radiant_win']\n",
    "scaler = StandardScaler()\n",
    "X.fillna(value=0, inplace=True)\n",
    "X_train = scaler.fit_transform(X)\n",
    "\n",
    "scores = []\n",
    "C = [0.00001, 0.001, 0.1, 1, 10, 1000, 100000, 10000000]\n",
    "kf = KFold(n=len(y_train.values), n_folds=5, shuffle=True, random_state=42)\n",
    "for c in C:\n",
    "    clf = LogisticRegression(C=c, random_state=42)\n",
    "    start_time = datetime.datetime.now()\n",
    "    score = cross_val_score(clf, X_train, y_train, cv=kf, scoring='roc_auc')\n",
    "    print 'Time elapsed: ', datetime.datetime.now() - start_time\n",
    "    print 'c:', c, ' Score:', score\n",
    "    scores.append(np.mean(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Выясните из данных, сколько различных идентификаторов героев существует в данной игре."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hero count: 112\n"
     ]
    }
   ],
   "source": [
    "print 'Hero count: ' + str(data_heroes.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Воспользуемся подходом \"мешок слов\" для кодирования информации о героях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = data_heroes.shape[0]\n",
    "X_pick = np.zeros((data.shape[0], N))\n",
    "\n",
    "for i, match_id in enumerate(data.index):\n",
    "    for p in xrange(5):\n",
    "        X_pick[i, data.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Проведите кросс-валидацию для логистической регрессии на новой выборке с подбором лучшего параметра регуляризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed:  0:00:07.923000\n",
      "c: 1e-05  Score: [ 0.71232219  0.71414825  0.71442411  0.71647376  0.71664742]\n",
      "Time elapsed:  0:00:19.797000\n",
      "c: 0.001  Score: [ 0.74890517  0.7522602   0.74929734  0.75585436  0.75156937]\n",
      "Time elapsed:  0:00:31.107000\n",
      "c: 0.1  Score: [ 0.74938328  0.75312868  0.7493699   0.75610595  0.75149897]\n",
      "Time elapsed:  0:00:31.032000\n",
      "c: 1  Score: [ 0.74937961  0.75312484  0.74936322  0.75609744  0.75148981]\n",
      "Time elapsed:  0:00:29.985000\n",
      "c: 10  Score: [ 0.74937942  0.753125    0.74936265  0.75609606  0.7514887 ]\n",
      "Time elapsed:  0:00:30.078000\n",
      "c: 1000  Score: [ 0.74937939  0.75312504  0.74936235  0.75609589  0.75148854]\n",
      "Time elapsed:  0:00:30.141000\n",
      "c: 100000  Score: [ 0.74937941  0.75312504  0.74936234  0.75609589  0.75148853]\n",
      "Time elapsed:  0:00:30.082000\n",
      "c: 10000000  Score: [ 0.74937941  0.75312504  0.74936234  0.75609589  0.75148853]\n"
     ]
    }
   ],
   "source": [
    "X = data.drop([\n",
    "    'duration', \n",
    "    'radiant_win', \n",
    "    'tower_status_radiant', \n",
    "    'tower_status_dire', \n",
    "    'barracks_status_radiant',\n",
    "    'barracks_status_dire',\n",
    "    'lobby_type',\n",
    "], axis=1)\n",
    "for n in range(1, 6):\n",
    "    X.drop(['r{}_hero'.format(n)], axis=1)\n",
    "    X.drop(['d{}_hero'.format(n)], axis=1)\n",
    "\n",
    "# forming bag-of-words      \n",
    "X_pick_transp = np.transpose(X_pick)\n",
    "for i in range(0, N):\n",
    "    X[\"bow_\"+str(i)] = pd.Series(X_pick_transp[i], index=data.index)\n",
    "\n",
    "y_train = data['radiant_win']\n",
    "scaler = StandardScaler()\n",
    "X.fillna(value=0, inplace=True)\n",
    "X_train = scaler.fit_transform(X)\n",
    "\n",
    "scores = []\n",
    "C = [0.00001, 0.001, 0.1, 1, 10, 1000, 100000, 10000000]\n",
    "kf = KFold(n=len(y_train.values), n_folds=5, shuffle=True, random_state=42)\n",
    "for c in C:\n",
    "    clf = LogisticRegression(C=c, random_state=42)\n",
    "    start_time = datetime.datetime.now()\n",
    "    score = cross_val_score(clf, X_train, y_train, cv=kf, scoring='roc_auc')\n",
    "    print 'Time elapsed: ', datetime.datetime.now() - start_time\n",
    "    print 'c:', c, ' Score:', score\n",
    "    scores.append(np.mean(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAHS9JREFUeJzt3X2MXXd95/H3xzMePyV+IJkEP8Ux\nxWtwQmo7gxfIwq6gqZxdlETaqthkeegieYEmaoPEYqQ2yqbqqmhh3ZZGSC4kgYbGBReEVdwauoFu\nqzXgyR3jxEkcjGHujMchk+Ze20nsGc/Md/+45zo34zszx/N07sPnJY0853d+99zfjeLz8fn9zvce\nRQRmZmZzsh6AmZnVBgeCmZkBDgQzM0s4EMzMDHAgmJlZwoFgZmaAA8HMzBIOBDMzAxwIZmaWaM16\nAJfj6quvjuuvvz7rYZiZ1ZUnnnjixYhon6hfXQXC9ddfT2dnZ9bDMDOrK5K60/TzlJGZmQEOBDMz\nSzgQzMwMcCCYmVnCgWBmZoADwczMEg4EMzMD6qwOwWbeheERzl0Y5vzgMOcuJD/J7+cvDHNucCRp\nG0r+HGF4ZOTSA0mXNlV5vyrdUJWeo/ulPla1xjpS58O3abT97dexbFHbjL6HA6FOjIwEA0MjrztJ\nn696wn7tRF4+qb9adf/I60765d+HRi7/GdujT1p+TLfZ9PvNDW90IDSbF18e4JOP5njxlYHXn7Av\nVPlX+AQkWDC3hQVzW5g/t4UFbS0Xt5csmMsbF88rbbe1Jn/Oqdp3fsXv5fZyn/mtc2htmdzMY1RJ\njmphMrqp6uuqHr/aseonrRysVqltkn/PLocDocb88Fg/P/nlS/zGW69l6cK5F0/C85MT8sK2aifp\nORf3V56w57XOqekpk2pjSzfc2v1MZvXMgVBjuvIFrpzfyu4P3cycOT7xmdns8V1GNSaXL7Jx9VKH\ngZnNOgdCDXl5YIhjz59h83XLsh6KmTUhB0INOdJTZCRg03VLsx6KmTWhVIEgaaukY5KOS9pZZf8u\nSYeTn+ckFSv2DVfs21fRvlbSjyX9TNLfSJrZ+6nqQC5fAGDTal8hmNnsmzAQJLUADwK3ARuA7ZI2\nVPaJiHsjYmNEbAS+CHyrYve58r6IuL2i/XPArohYBxSAj03xs9S9rnyRN19zBUsWzs16KGbWhNJc\nIWwBjkfEiYgYBPYAd4zTfzvw2HgHVOl+w/cCe5OmrwJ3phhLw4oIunqKbPZ0kZllJE0grAR6KrZ7\nk7ZLSFoDrAUer2ieL6lT0o8klU/6VwHFiBhKccwdyes7+/v7Uwy3Pv3yX1/lpVcG2eQFZTPLSJo6\nhGr3P45VQ7kN2BsRwxVt10VEn6Q3AY9LehI4k/aYEbEb2A3Q0dHRsLWbue7S+oHvMDKzrKS5QugF\nVldsrwL6xui7jVHTRRHRl/x5AvghsAl4EVgqqRxI4x2zKeTyBa6c18q6a67Ieihm1qTSBMIhYF1y\nV1AbpZP+vtGdJK0HlgEHK9qWSZqX/H41cAvwdJS+jOYHwG8lXT8CfGcqH6TedeWLbLzOBWlmlp0J\nAyGZ578bOAA8A3wjIo5KekBS5V1D24E98fpvHnsr0Cnpp5QC4E8i4ulk32eAT0k6TmlN4StT/zj1\n6ZWBIZ59/ozXD8wsU6m+yygi9gP7R7XdN2r7/iqv+3/A28Y45glKdzA1vZ/2uiDNzLLnSuUa0JUv\n1fFtdkGamWXIgVADct0Ffq19kQvSzCxTDoSMvVaQ5qsDM8uWAyFj3UlB2uY1DgQzy5YDIWMXv9DO\nC8pmljEHQsZy+QJXzGtl3TVXZj0UM2tyDoSM5bpLT0hrcUGamWXMgZChVwdLBWn+hlMzqwUOhAz9\ntOd0qSDNC8pmVgMcCBl67QlpvkIws+w5EDLUlS/wpvZFLF3Y9E8PNbMa4EDISESQy7sgzcxqhwMh\nI/mXkoI0B4KZ1QgHQkbK6web13j9wMxqgwMhI7nuogvSzKymOBAykssX+PXVS1yQZmY1w4GQgVJB\n2lmvH5hZTUkVCJK2Sjom6biknVX275J0OPl5TlJx1P7Fkk5K+ouKth8mxyy/7pqpf5z6cKT3NMMj\n4UAws5oy4SM0JbUADwK3Ar3AIUn7Kp6NTETcW9H/HmDTqMP8EfBPVQ5/V0R0Tmbg9ay8oLzRBWlm\nVkPSXCFsAY5HxImIGAT2AHeM03878Fh5Q9LNwLXA96Yy0EaS6y7ypqsXsWyRC9LMrHakCYSVQE/F\ndm/SdglJa4C1wOPJ9hzgC8Cnxzj2w8l00R9KaorV1YigK19gk6eLzKzGpAmEaifqGKPvNmBvRAwn\n258E9kdET5W+d0XE24B3Jz8fqvrm0g5JnZI6+/v7Uwy3tuVfepV/fWXQ9QdmVnPSBEIvsLpiexXQ\nN0bfbVRMFwHvBO6W9Evg88CHJf0JQEScTP48C/w1pampS0TE7ojoiIiO9vb2FMOtbV350nq7F5TN\nrNZMuKgMHALWSVoLnKR00v/g6E6S1gPLgIPltoi4q2L/R4GOiNgpqRVYGhEvSpoLvB/4x6l8kHqR\nyxdY1NbCv7nWBWlmVlsmDISIGJJ0N3AAaAEeioijkh4AOiNiX9J1O7AnIsaaTqo0DziQhEELpTD4\ny0l9gjpTKkjzE9LMrPakuUIgIvYD+0e13Tdq+/4JjvEI8Ejy+yvAzemH2RheHRzimVNn+cS//7Ws\nh2JmdglXKs+iiwVpXlA2sxrkQJhF5QXlTau9oGxmtceBMIty+YIL0sysZjkQZkm5IG3jdZ4uMrPa\n5ECYJT0vnePFl/2ENDOrXQ6EWXLxCWkOBDOrUQ6EWdKVFKStf6ML0sysNjkQZkkuX3RBmpnVNAfC\nLDg3OMwzp86wyQvKZlbDHAiz4EhvkSE/Ic3MapwDYRbkygVpDgQzq2EOhFnQlS+w9upFvMEFaWZW\nwxwIMywiyOWLXj8ws5rnQJhhvYVzvPjygKeLzKzmORBm2GsFab5CMLPa5kCYYbnuAgvbWljvJ6SZ\nWY1zIMywrp4iv75qKa0t/k9tZrXNZ6kZdP7CME/3nfEDccysLqQKBElbJR2TdFzSzir7d0k6nPw8\nJ6k4av9iSScl/UVF282SnkyO+eeSGu47HY70nmZoJPxAHDOrCxMGgqQW4EHgNmADsF3Shso+EXFv\nRGyMiI3AF4FvjTrMHwH/NKrtS8AOYF3ys3VSn6CGlReUfcupmdWDNFcIW4DjEXEiIgaBPcAd4/Tf\nDjxW3pB0M3At8L2KtuXA4og4GBEBfA24cxLjr2m57gLXX7WQq66Yl/VQzMwmlCYQVgI9Fdu9Sdsl\nJK0B1gKPJ9tzgC8An65yzN40x6xXEUFXT9HfX2RmdSNNIFSb248x+m4D9kbEcLL9SWB/RPSM6pf6\nmJJ2SOqU1Nnf359iuLWht3CO/rMDbFrjQDCz+tCaok8vsLpiexXQN0bfbcDvVmy/E3i3pE8CVwBt\nkl4G/iw5zoTHjIjdwG6Ajo6OsYKo5lxcP1jt9QMzqw9pAuEQsE7SWuAkpZP+B0d3krQeWAYcLLdF\nxF0V+z8KdETEzmT7rKR3AD8GPkxpMbphdOWLLGxr4S1+QpqZ1YkJp4wiYgi4GzgAPAN8IyKOSnpA\n0u0VXbcDe5JF4jQ+AXwZOA78HPj7yxp5jcvlC9y0aokL0sysbqS5QiAi9gP7R7XdN2r7/gmO8Qjw\nSMV2J3BjumHWl3JB2o73vCnroZiZpeZ/vs6AJ0+e9hPSzKzuOBBmQK67tKC80QVpZlZHHAgzIJcv\nsOaqhVztgjQzqyMOhGlWfkKap4vMrN44EKbZyWKpIM0PxDGzeuNAmGa5fOmLXv3ITDOrNw6EaZbr\nLrBgrgvSzKz+OBCmWZcL0sysTvmsNY3OXxjmaN8ZNvsL7cysDjkQptFTLkgzszrmQJhGfkKamdUz\nB8I0ynUXue4NLkgzs/rkQJgmpYK0gusPzKxuORCmycniOV44O+AFZTOrWw6EaVIuSPOCspnVKwfC\nNOnKF5g/dw7rXZBmZnXKgTBNcvkiN61aylwXpJlZnfLZaxqUnpB22tNFZlbXUgWCpK2Sjkk6Lmln\nlf27JB1Ofp6TVEza10h6Imk/KunjFa/5YXLM8uuumb6PNbueOnmaC8PhO4zMrK5N+ExlSS3Ag8Ct\nQC9wSNK+iHi63Cci7q3ofw+wKdk8BbwrIgYkXQE8lby2L9l/V/Js5br2WkGarxDMrH6luULYAhyP\niBMRMQjsAe4Yp/924DGAiBiMiIGkfV7K96s7Xfkiq9+wgPYrXZBmZvUrzQl6JdBTsd2btF1C0hpg\nLfB4RdtqSUeSY3yu4uoA4OFkuugPJWmMY+6Q1Cmps7+/P8VwZ9drBWm+OjCz+pYmEKqdqGOMvtuA\nvRExfLFjRE9E3AS8GfiIpGuTXXdFxNuAdyc/H6p2wIjYHREdEdHR3t6eYrizq+/0eX51ZsCBYGZ1\nL00g9AKrK7ZXAX1j9N1GMl00WnJlcJTSyZ+IOJn8eRb4a0pTU3Un111aP3AgmFm9SxMIh4B1ktZK\naqN00t83upOk9cAy4GBF2ypJC5LflwG3AMcktUq6OmmfC7wfeGqqHyYLuaQg7S3LXZBmZvVtwruM\nImJI0t3AAaAFeCgijkp6AOiMiHI4bAf2RETldNJbgS9ICkpTT5+PiCclLQIOJGHQAvwj8JfT97Fm\nT1e+yE0rXZBmZvVvwkAAiIj9wP5RbfeN2r6/yuu+D9xUpf0V4ObLGWgtKj0h7TT/9d+tzXooZmZT\n5n/WTsHRvnJBmtcPzKz+ORCmINftbzg1s8bhQJiCXL7ggjQzaxgOhCnoyhfZtNpXB2bWGBwIk9RX\nPMfzZ877C+3MrGE4ECap/IV2fmSmmTUKB8Ik5bqLzJ87h7cuX5z1UMzMpoUDYZJy+YIL0sysofhs\nNgkDQ8M83XeGTV4/MLMG4kCYhKdOnmFweMQPxDGzhuJAmISuiwvKvkIws8bhQJiEXL7AqmULuObK\n+VkPxcxs2jgQJiHXXfTXVZhZw3EgXKZTp0sFaV5QNrNG40C4TP5COzNrVA6Ey5TLF5jX6oI0M2s8\nDoTLlMsXuGnVEtpa/Z/OzBpLqrOapK2Sjkk6Lmlnlf27JB1Ofp6TVEza10h6Imk/KunjFa+5WdKT\nyTH/XJKm72PNjIGhYY6ePOPpIjNrSBM+QlNSC/AgcCvQCxyStC8ini73iYh7K/rfA2xKNk8B74qI\nAUlXAE8lr+0DvgTsAH5E6fGcW4G/n56PNTOO9pUL0rygbGaNJ80VwhbgeESciIhBYA9wxzj9twOP\nAUTEYEQMJO3zyu8naTmwOCIORkQAXwPunORnmDW57qQgzVcIZtaA0gTCSqCnYrs3abuEpDXAWuDx\nirbVko4kx/hccnWwMjnOhMesJV35IiuXLuCaxS5IM7PGkyYQqs3txxh9twF7I2L4YseInoi4CXgz\n8BFJ117OMSXtkNQpqbO/vz/FcGdOLl/w8w/MrGGlCYReYHXF9iqgb4y+20imi0ZLrgyOAu9Ojrkq\nzTEjYndEdERER3t7e4rhzoxTp89x6rSfkGZmjStNIBwC1klaK6mN0kl/3+hOktYDy4CDFW2rJC1I\nfl8G3AIci4hTwFlJ70juLvow8J0pf5oZ1JUvFaT5G07NrFFNeJdRRAxJuhs4ALQAD0XEUUkPAJ0R\nUQ6H7cCeZJG47K3AFyQFpWmiz0fEk8m+TwCPAAso3V1U03cY5bpLBWkbXJBmZg1qwkAAiIj9lG4N\nrWy7b9T2/VVe933gpjGO2QncmHagWcvlC7xtpQvSzKxx+eyWwsDQME+dPOMFZTNraA6EFMoFaV5Q\nNrNG5kBIwQvKZtYMHAgp5PIFVi5dwLUuSDOzBuZASKGru+DvLzKzhudAmMDzp8/Td/q8v7/IzBqe\nA2ECuXzyhXa+w8jMGpwDYQJd+QJtLkgzsybgQJhALl90QZqZNQWf5cYxODTCkydPu/7AzJqCA2Ec\nR/tOMzg04gVlM2sKDoRx5JKCNC8om1kzcCCMoytfYMWS+S5IM7Om4EAYR1e+yCZfHZhZk3AgjOFX\nZ85zsnjO6wdm1jQcCGPIdScFab7DyMyahANhDLmkIO2GFUuyHoqZ2axwIIyhK1/kxhWLXZBmZk0j\n1dlO0lZJxyQdl7Szyv5dkg4nP89JKibtGyUdlHRU0hFJH6h4zSOSflHxuo3T97GmZnBohCMnT3v9\nwMyayoTPVJbUAjwI3Ar0Aock7YuIp8t9IuLeiv73AJuSzVeBD0fEzyStAJ6QdCAiisn+T0fE3mn6\nLNPm6VNnSgVpvsPIzJpImiuELcDxiDgREYPAHuCOcfpvBx4DiIjnIuJnye99wAtA+9SGPPNeW1B2\nIJhZ80gTCCuBnort3qTtEpLWAGuBx6vs2wK0AT+vaP7jZCppl6R5qUc9w3JJQdobl7ggzcyaR5pA\nUJW2GKPvNmBvRAy/7gDScuCvgN+JiJGk+bPAW4C3A28APlP1zaUdkjoldfb396cY7tR15Yt+frKZ\nNZ00gdALrK7YXgX0jdF3G8l0UZmkxcB3gT+IiB+V2yPiVJQMAA9Tmpq6RETsjoiOiOhob5/52aYX\nkoI0PzLTzJpNmkA4BKyTtFZSG6WT/r7RnSStB5YBByva2oBvA1+LiG+O6r88+VPAncBTk/0Q08lP\nSDOzZjXhXUYRMSTpbuAA0AI8FBFHJT0AdEZEORy2A3sionI66beB9wBXSfpo0vbRiDgMfF1SO6Up\nqcPAx6flE01RLl+krWUON6zwE9LMrLlMGAgAEbEf2D+q7b5R2/dXed2jwKNjHPO9qUc5i3LdBW5Y\nuZh5rS1ZD8XMbFa5DLfCa09I83SRmTUfB0KFZ06dYcBPSDOzJuVAqPDagrLvMDKz5uNAqJDLF1m+\nZD7LlyzIeihmZrPOgVAh111w/YGZNS0HQuIFPyHNzJqcAyGRy5e+gNVfWWFmzcqBkOjKF2hrmcON\nK12QZmbNyYGQyOVdkGZmzc2BQPKEtN7TbFrt6SIza14OBODZ55OCNNcfmFkTcyDgJ6SZmYEDASjd\nYfTGxfNZsdQFaWbWvBwIlBaUPV1kZs2u6QPhhbPn6S2c84KymTW9pg+EXHepIM1XCGbW7Jo+ELp6\nCsxtETesWJL1UMzMMuVA6C5yw4olzJ/rgjQza26pAkHSVknHJB2XtLPK/l2SDic/z0kqJu0bJR2U\ndFTSEUkfqHjNWkk/lvQzSX8jqW36PlY6F4ZHOHKy6NtNzcxIEQiSWoAHgduADcB2SRsq+0TEvRGx\nMSI2Al8EvpXsehX4cETcAGwF/lRSebL+c8CuiFgHFICPTccHuhzPnDrD+Qsj/sprMzPSXSFsAY5H\nxImIGAT2AHeM03878BhARDwXET9Lfu8DXgDaJQl4L7A3ec1XgTsn9xEm72JB2hpfIZiZpQmElUBP\nxXZv0nYJSWuAtcDjVfZtAdqAnwNXAcWIGEpxzB2SOiV19vf3pxhuel09Ra5dPI8VS+ZP63HNzOpR\nmkBQlbYYo+82YG9EDL/uANJy4K+A34mIkcs5ZkTsjoiOiOhob29PMdz0cvkCm69bRumCxcysuaUJ\nhF5gdcX2KqBvjL7bSKaLyiQtBr4L/EFE/ChpfhFYKqk1xTFnRP/ZAXpe8hPSzMzK0gTCIWBdcldQ\nG6WT/r7RnSStB5YBByva2oBvA1+LiG+W2yMigB8Av5U0fQT4zmQ/xGTk8qX1Ay8om5mVTBgIyTz/\n3cAB4BngGxFxVNIDkm6v6Lod2JOc7Mt+G3gP8NGK21I3Jvs+A3xK0nFKawpfmYbPk1ouXypIu3Gl\nC9LMzABaJ+4CEbEf2D+q7b5R2/dXed2jwKNjHPMEpTuYMtGVL7LBBWlmZhc1ZaXyheERjvQW2ezp\nIjOzi5oyEJ49dZbzF0a8oGxmVqEpA8ELymZml2raQLjmynms9BPSzMwuaspA6MoXXZBmZjZK0wXC\niy8PkH/pVT8Qx8xslKYLhItfaOcFZTOz12m+QMgXaZ3jgjQzs9GaMBAK3LBisQvSzMxGaapAGEoK\n0jZ5usjM7BJNFQjPPp8UpPmBOGZml2iqQCgXpPkrK8zMLtVcgdBdoN0FaWZmVTVXIORLX2jngjQz\ns0s1TSBcLEjzgrKZWVVNEwhd+SKAF5TNzMbQNIGQyxdonSPe5oI0M7OqUgWCpK2Sjkk6Lmlnlf27\nKh6R+ZykYsW+f5BUlPR3o17ziKRfVHm05ozIdRfY4II0M7MxTfgITUktwIPArUAvcEjSvoh4utwn\nIu6t6H8PsKniEP8LWAj8tyqH/3RE7J3k2FMrFaSd5gNvXz3Tb2VmVrfSXCFsAY5HxImIGAT2AHeM\n03878Fh5IyL+D3B2SqOcomefP8u5C8N+II6Z2TjSBMJKoKdiuzdpu4SkNcBa4PGU7//Hko4kU07z\nUr7msnXl/Q2nZmYTSRMI1W7ajzH6bgP2RsRwiuN+FngL8HbgDcBnqr65tENSp6TO/v7+FIe9VC5f\npP3Keaxa5oI0M7OxpAmEXqBy8n0V0DdG321UTBeNJyJORckA8DClqalq/XZHREdEdLS3t6c59CXW\nXXsF/3nzKhekmZmNY8JFZeAQsE7SWuAkpZP+B0d3krQeWAYcTPPGkpZHxCmVztJ3Ak+lHvVl+uR/\nePNMHdrMrGFMGAgRMSTpbuAA0AI8FBFHJT0AdEbEvqTrdmBPRLxuOknSP1OaGrpCUi/wsYg4AHxd\nUjulKanDwMen7VOZmdll06jzd03r6OiIzs7OrIdhZlZXJD0RER0T9WuaSmUzMxufA8HMzAAHgpmZ\nJRwIZmYGOBDMzCzhQDAzM6DObjuV1A90T/LlVwMvTuNwZlo9jddjnTn1NN56GivU13inOtY1ETHh\nVz3UVSBMhaTONPfh1op6Gq/HOnPqabz1NFaor/HO1lg9ZWRmZoADwczMEs0UCLuzHsBlqqfxeqwz\np57GW09jhfoa76yMtWnWEMzMbHzNdIVgZmbjaPhAkPSQpBckzdjzFqaLpNWSfiDpGUlHJf1e1mMa\nj6T5kn4i6afJeP9H1mOaiKQWSV2S/i7rsUxE0i8lPSnpsKSa/ppfSUsl7ZX0bPL/7zuzHtNYJK1P\n/puWf85I+v2sxzUWSfcmf7+ekvSYpPkz9l6NPmUk6T3Ay8DXIuLGrMczHknLgeURkZN0JfAEcGdE\nPJ3x0KpKHm60KCJeljQX+Bfg9yLiRxkPbUySPgV0AIsj4v1Zj2c8kn4JdEREzd8rL+mrwD9HxJcl\ntQELI6KY9bgmIqmF0oO//m1ETLbGacZIWknp79WGiDgn6RvA/oh4ZCber+GvECLi/wIvZT2ONJLH\niuaS388CzwArsx3V2JJHoL6cbM5Nfmr2XxiSVgH/Cfhy1mNpJJIWA+8BvgIQEYP1EAaJ9wE/r8Uw\nqNAKLJDUCixk7EcYT1nDB0K9knQ9sAn4cbYjGV8yBXMYeAH4fkTU8nj/FPjvwEjWA0kpgO9JekLS\njqwHM443Af3Aw8l03JclLcp6UCmlfg58FiLiJPB5IA+cAk5HxPdm6v0cCDVI0hXA3wK/HxFnsh7P\neCJiOCI2AquALZJqclpO0vuBFyLiiazHchluiYjNwG3A7ybTn7WoFdgMfCkiNgGvADuzHdLEkqmt\n24FvZj2WsUhaBtwBrAVWAIsk/ZeZej8HQo1J5uL/Fvh6RHwr6/GklUwR/BDYmvFQxnILcHsyL78H\neK+kR7Md0vgioi/58wXg28CWbEc0pl6gt+LqcC+lgKh1twG5iPhV1gMZx28Av4iI/oi4AHwLeNdM\nvZkDoYYki7RfAZ6JiP+d9XgmIqld0tLk9wWU/ud9NttRVRcRn42IVRFxPaVpgscjYsb+pTVVkhYl\nNxaQTL/8JlCTd8pFxPNAj6T1SdP7gJq8EWKU7dTwdFEiD7xD0sLk/PA+SmuLM6LhA0HSY8BBYL2k\nXkkfy3pM47gF+BClf72Wb4n7j1kPahzLgR9IOgIcorSGUPO3c9aJa4F/kfRT4CfAdyPiHzIe03ju\nAb6e/L+wEfifGY9nXJIWArdS+hd3zUquuvYCOeBJSufsGatabvjbTs3MLJ2Gv0IwM7N0HAhmZgY4\nEMzMLOFAMDMzwIFgZmYJB4KZmQEOBDMzSzgQzMwMgP8PCXwn3tYu/pMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5bf9240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([1, 2, 3, 4, 5, 6, 7, 8], scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Постройте предсказания вероятностей победы команды Radiant для тестовой выборки с помощью лучшей из изученных моделей (лучшей с точки зрения AUC-ROC на кросс-валидации)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min0.00892501228453\n",
      "max0.996509452456\n"
     ]
    }
   ],
   "source": [
    "# Forming test features -----------------------------------------------\n",
    "N = data_heroes.shape[0]\n",
    "X_pick = np.zeros((data_test.shape[0], N))\n",
    "for i, match_id in enumerate(data_test.index):\n",
    "    for p in xrange(5):\n",
    "        X_pick[i, data_test.loc[match_id, 'r%d_hero' % (p+1)]-1] = 1\n",
    "        X_pick[i, data_test.loc[match_id, 'd%d_hero' % (p+1)]-1] = -1\n",
    "        \n",
    "X = data_test.drop(['lobby_type'], axis=1)\n",
    "for n in range(1, 6):\n",
    "    X.drop(['r{}_hero'.format(n)], axis=1)\n",
    "    X.drop(['d{}_hero'.format(n)], axis=1)\n",
    "\n",
    "# forming bag-of-words      \n",
    "X_pick_transp = np.transpose(X_pick)\n",
    "for i in range(0, N):\n",
    "    X[\"bow_\"+str(i)] = pd.Series(X_pick_transp[i], index=data_test.index)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X.fillna(value=0, inplace=True)\n",
    "X_test = scaler.fit_transform(X)\n",
    "\n",
    "# Test\n",
    "clf.fit(X_train, y_train)\n",
    "prob_pos = clf.predict_proba(X_test)\n",
    "\n",
    "print 'min ' + str(min(prob_pos[:, 1]))\n",
    "print 'max ' + str(max(prob_pos[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
